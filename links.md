---
layout: page
title: "ML Resources"
description: "A list of technical readings that I enjoy"
header-img: "img/galaxy.jpg"
---

An opiniated collection of Python-centric ML resources that I have found to be particularly useful during my time in Data Science.

### Data Visualization

- [`Altair`](https://github.com/altair-viz/altair) - Altair is a declarative statistical visualization library for Python, based on Vega and Vega-Lite. The documentation for this library can be found [`here`](https://altair-viz.github.io/index.html)
- [`Bokeh`](https://github.com/bokeh/bokeh) - Bokeh is a Python library for creating interactive visualizations for modern web browsers. The documentation for this library can be found [`here`](https://docs.bokeh.org/en/latest/).
- [`Dash`](https://github.com/plotly/dash) - Written on top of Plotly.js and React.js, Dash is ideal for building and deploying data apps with customized user interfaces. The documentation for this library can be found [`here`](https://dash.plotly.com/introduction).
- [`diagrams`](https://github.com/mingrammer/diagrams) - diagrams lets you draw the cloud system architecture in Python code. The documentation for this library can be found [`here`](https://diagrams.mingrammer.com/docs/getting-started/installation#quick-start).
- [`folium`](https://github.com/python-visualization/folium) - makes it easy to visualize data that’s been manipulated in Python on an interactive leaflet map. The documentation for this library can be found [`here`](https://python-visualization.github.io/folium/).
- [`igraph`](https://github.com/igraph/python-igraph) - a library for creating and manipulating graphs. It is intended to be as powerful (ie. fast) as possible to enable the analysis of large graphs. The documentation for this library can be found [`here`](https://igraph.org/python/).
- [`matplotlib`](https://github.com/matplotlib/matplotlib) - a comprehensive library for creating static, animated, and interactive visualizations in Python. The documentation for this library can be found [`here`](https://matplotlib.org/stable/).
- [`networkx`](https://github.com/networkx/networkx) - a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks. The documentation for this library can be found [`here`](https://networkx.org/documentation/stable/tutorial.htmle/).
- [`pandas-profiling`](https://github.com/ydataai/pandas-profiling) - Create HTML profiling reports from pandas DataFrame objects. The documentation for this library can be found [`here`](https://pandas-profiling.ydata.ai/docs/master/index.html).
- [`Plotly`](https://github.com/plotly/plotly.py) - Plotly's Python graphing library makes interactive, publication-quality graphs. The documentation for this library can be found [`here`](https://plotly.com/python/)
- [`plotnine`](https://github.com/has2k1/plotnine) - an implementation of a grammar of graphics in Python, it is based on R's `ggplot2` library. The documentation for this library can be found [`here`](https://plotnine.readthedocs.io/en/stable/index.html)
- [`seaborn`](https://github.com/mwaskom/seaborn) - a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.. The documentation for this library can be found [`here`](https://seaborn.pydata.org/).
- [`Streamlit`](https://github.com/streamlit/streamlit) - Streamlit turns data scripts into shareable web apps in minutes. All in pure Python. No front‑end experience required. The documentation for this library can be found [`here`](https://streamlit.io/).

### General Purpose (Tabular) Machine Learning

- [`annoy`](https://github.com/spotify/annoy) - approximate Nearest Neighbors in C++/Python optimized for memory usage and loading/saving to disk.
- [`imbalanced-learn`](https://github.com/scikit-learn-contrib/imbalanced-learn) - a Python package to tackle the curse of imbalanced datasets in Machine Learning. The documentation for this library can be found [`here`](https://imbalanced-learn.org/stable/).
- [`hummingbird`](https://github.com/microsoft/hummingbird) - a library for compiling trained traditional ML models into tensor computations. The documentation for this library can be found [`here`](https://microsoft.github.io/hummingbird/).
- [`lifetimes`](https://github.com/CamDavidsonPilon/lifetimes) - a Python library to help model customer behavior and measure Customer Lifetime Value. The documentation for this library can be found [`here`](https://lifetimes.readthedocs.io/en/latest/index.html).
- [`metric-learn`](https://github.com/scikit-learn-contrib/metric-learn) - efficient Python implementations of several popular supervised and weakly-supervised metric learning algorithms. The documentation for this library can be found [`here`](http://contrib.scikit-learn.org/metric-learn/).
- [`milk`](https://github.com/luispedro/milk) - Machine learning toolkit in Python with a strong emphasis on speed and low memory usage. The documentation for this library can be found [`here`](https://pythonhosted.org/milk/).
Its focus is on supervised classification with several classifiers available: SVMs (based on libsvm), k-NN, random forests, decision trees.
- [`pyBrain`](https://github.com/pybrain/pybrain) - a Python library to develop and implement neural networks. The documentation for this library can be found [`here`]http://pybrain.org/docs/index.html).
- [`pycaret`](https://github.com/pycaret/pycaret) - a low-code machine learning library in Python that automates machine learning workflows. The documentation for this library can be found [`here`](https://pycaret.org/).
- [`pymc3`](https://github.com/pymc-devs/pymc) - a probabilistic programming library for Python that allows users to build Bayesian models with a simple Python API. The documentation for this library can be found [`here`](https://www.pymc.io/welcome.html).
- [`scikit-learn`](https://github.com/scikit-learn/scikit-learn) - Multi-purpose Machine Learning library in Python. The documentation for this library can be found [`here`](https://scikit-learn.org/stable/user_guide.html).
- [`statsmodel`](https://github.com/statsmodels/statsmodels) - a Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests, and statistical data exploration. The documentation for this library can be found [`here`](https://www.statsmodels.org/stable/index.html).
- [`XGBoost`](https://github.com/dmlc/xgboost) - XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. The documentation for this library can be found [`here`](https://xgboost.readthedocs.io/en/stable/).


### ML Explanability and Feature Interpretation

- [`eli5`](https://github.com/eli5-org/eli5) - a Python library for debugging/inspecting machine learning classifiers and explaining their predictions. The documentation for this library can be found [`here`](https://eli5.readthedocs.io/en/latest/overview.html).
- [`lime`](https://github.com/marcotcr/lime) - a Python library to help explain the predictions of any machine learning classifier. A more thorough explanation of the methodology is available [`here`](https://arxiv.org/abs/1602.04938).
- [`omniXAI`](https://github.com/salesforce/OmniXAI) - a Python machine-learning library for explainable AI (XAI), offering omni-way explainable AI and interpretable machine learning capabilities. The documentation for this library can be found [`here`](https://opensource.salesforce.com/OmniXAI/latest/index.html).
- [`shap`](https://github.com/slundberg/shap) - a game theoretic approach to explain the output of any machine learning model.
- [`yellowbrick`](https://github.com/DistrictDataLabs/yellowbrick/tree/main) - a Python library that provides a suite of visual analysis and diagnostic tools to facilitate machine learning model selection. The documentation for this library can be found [`here`](https://www.scikit-yb.org/en/latest/).

### Hyper-parameter Optimization

- [`hyperopt`](https://github.com/hyperopt/hyperopt) - distributed Asynchronous Hyper-parameter Optimization. The documentation for this library can be found [`here`](http://hyperopt.github.io/hyperopt/).
- [`optuna`](https://github.com/optuna/optuna) - an open source hyperparameter optimization framework to automate hyperparameter search. The documentation for this library can be found [`here`](https://optuna.org/).
- [`ray`](https://github.com/ray-project/ray) - an open source framework  packaged with RLlib, a scalable reinforcement learning library, and Tune, a scalable hyperparameter tuning library. The documentation for this library can be found [`here`](https://docs.ray.io/en/latest/tune/index.html).
- [`scikit-optimize`](https://github.com/scikit-optimize/scikit-optimize) - a simple and efficient library that implements several methods for sequential model-based optimization. The documentation for this library can be found [`here`](https://scikit-optimize.github.io/stable/index.html).
- [`tpot`](https://github.com/EpistasisLab/tpot) - a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming. The documentation for this library can be found [`here`](http://epistasislab.github.io/tpot/).

### Time Series

- [`Auto_TS`](https://github.com/AutoViML/Auto_TS) - Automatically build ARIMA, SARIMAX, VAR, FB Prophet and XGBoost Models on Time Series data sets with a Single Line of Code. The documentation for this library can be found [`here`](https://github.com/AutoViML/Auto_TS)
- [`darts`](https://github.com/unit8co/darts) - a Python library for easy manipulation and forecasting of time series. It contains a variety of models, from classics such as ARIMA to deep neural networks. The documentation for this library can be found [`here`](https://unit8co.github.io/darts/).
- [`luminol`](https://github.com/linkedin/luminol) - a lightweight python library for time series data analysis. The two major functionalities it supports are anomaly detection and correlation. The documentation for this library can be found [`here`](https://github.com/linkedin/luminol).
- [`Prophet`](https://github.com/facebook/prophet) - a library for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. The documentation for this library can be found [`here`](https://facebook.github.io/prophet/).
- [`sktime`](https://github.com/alan-turing-institute/sktime) - provides an easy-to-use, flexible and modular open-source framework for a wide range of time series machine learning tasks. The documentation for this library can be found [`here`](https://www.sktime.org/en/stable/).
- [`statsforecast`](https://github.com/Nixtla/statsforecast) - lightning fast forecasting with statistical and econometric models. The documentation for this library can be found [`here`](https://nixtla.github.io/statsforecast/#lightning-fast-forecasting-with-statistical-and-econometric-mode).
- [`tsfresh`](https://github.com/blue-yonder/tsfresh) - automates the extraction of relevant features from time series data. The documentation for this library can be found [`here`](https://tsfresh.readthedocs.io/en/latest/text/introduction.html).
- [`pyod`](https://github.com/yzhao062/pyod) - a Python toolkit that provides access to a wide range of outlier detection algorithms for detecting outliers in multivariate data. The documentation for this library can be found [`here`](https://pyod.readthedocs.io/en/latest/).
- [`pyts`](https://github.com/johannfaouzi/pyts) - a Python package dedicated to time series classification. It aims to make time series classification easily accessible by providing preprocessing and utility tools, and implementations of several time series classification algorithms. The documentation for this library can be found [`here`](https://pyts.readthedocs.io/en/stable/).

### Survival Analysis

- [`lifelines`](https://github.com/CamDavidsonPilon/lifelines) - a complete survival analysis library, written in pure Python. The documentation for this library can be found [`here`](https://lifelines.readthedocs.io/en/latest/).
- [`scikit-survival`](https://github.com/sebp/scikit-survival) - a Python module for survival analysis built on top of scikit-learn. The documentation for this library can be found [`here`](https://scikit-survival.readthedocs.io/en/stable/user_guide/00-introduction.html).
- [`pysurvival`](https://github.com/square/pysurvival/) - an open source python package for Survival Analysis modeling built upon the most commonly used machine learning packages such as NumPy, SciPy and PyTorch. The documentation for this library can be found [`here`](https://square.github.io/pysurvival/).


### Causal Inference

- [`Causal ML`](https://github.com/uber/causalml) - provides a suite of uplift modeling and causal inference methods that allows user to estimate the Conditional Average Treatment Effect (CATE) or Individual Treatment Effect (ITE) from experimental or observational data. The documentation for this library can be found [`here`](https://causalml.readthedocs.io/en/latest/about.html).
- [`doWhy`](https://github.com/py-why/dowhy) - An end-to-end library for causal inference. The documentation for this library can be found [`here`](https://py-why.github.io/dowhy/).
- [`EconML`](https://github.com/Microsoft/EconML) - applies machine learning techniques to estimate individualized causal responses from observational or experimental data. The suite of estimation methods provided in EconML represents the latest advances in causal machine learning. The documentation for this library can be found [`here`](https://www.microsoft.com/en-us/research/project/econml/).
- [`scikit-uplift`](https://github.com/maks-sh/scikit-uplift) - an uplift modeling python package that provides fast sklearn-style models implementation, evaluation metrics and visualization tools. The documentation for this library can be found [`here`](https://www.uplift-modeling.com/en/latest/index.html).


### Recommendation \& Ranking

- [`lightFM`](https://github.com/lyst/lightfm) - LightFM is a Python implementation of a number of popular recommendation algorithms for both implicit and explicit feedback. The documentation for this library can be found [`here`](https://making.lyst.com/lightfm/docs/home.html).
- [`surprise`](https://github.com/NicolasHug/Surprise) - a Python scikit for building and analyzing recommender systems. The documentation for this library can be found [`here`](http://surpriselib.com/).
- [`pyTerrier`](https://github.com/terrier-org/pyterrier) - a Python framework for performing information retrieval experiments and implementing learn-to-rank pipelines. The documentation for this library can be found [`here`](https://pyterrier.readthedocs.io/en/latest/).
- [`python-recsys`](https://github.com/ocelma/python-recsys) - a python library for implementing a recommender system. The documentation for this library can be found [`here`](http://ocelma.net/software/python-recsys/build/html/).

### Natural Language Processing

- [`allennlp`](https://github.com/allenai/allennlp) - an open-source NLP research library, built on PyTorch. The documentation for this library can be found [`here`](https://www.allennlp.org/).
- [`bert-embedding`](https://github.com/imgarylai/bert-embedding) - token level embeddings from BERT model on mxnet and gluonnlp. The documentation for this library can be found [`here`](https://bert-embedding.readthedocs.io/en/latest/).
- [`fastText`](https://github.com/facebookresearch/fastText) - a library for efficient learning of word representations and sentence classification. The documentation for this library can be found [`here`](https://fasttext.cc/).
- [`flair`](https://github.com/flairNLP/flair) - a very simple framework for NLP that ships with state-of-the-art models for a range of NLP tasks. The documentation for this library can be found [`here`](https://github.com/flairNLP/flair/tree/master/resources/docs).
- [`fuzzywuzzy`](https://github.com/seatgeek/fuzzywuzzy) - About
Fuzzy String Matching in Python. The documentation for this library can be found [`here`](https://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/).
- [`gensim`](https://github.com/RaRe-Technologies/gensim) - a free open-source Python library for representing documents as semantic vectors. The documentation for this library can be found [`here`](https://radimrehurek.com/gensim/auto_examples/index.html).
- [`NLTK`](https://github.com/nltk/nltk) - a leading platform for building Python programs to work with human language data. The documentation for this library can be found [`here`](https://www.nltk.org/).
- [`Stanford CoreNLP Python`](https://github.com/dasmith/stanford-corenlp-python) - a Python wrapper for Stanford CoreNLP tools.
- [`spacy`](https://github.com/explosion/spaCy) - a library for advanced Natural Language Processing in Python and Cython. The documentation for this library can be found [`here`](https://spacy.io/usage).
- [`stanza`](https://github.com/stanfordnlp/stanza) - the Stanford NLP Group's official Python NLP library. It contains support for running various accurate natural language processing tools on 60+ languages and for accessing the Java Stanford CoreNLP software from Python. The documentation for this library can be found [`here`](https://stanfordnlp.github.io/stanza/).
- [`textblob`](https://github.com/sloria/TextBlob) - a Python library for processing textual data. It provides a consistent API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction. The documentation for this library can be found [`here`](https://spacy.io/usage).
- [`transformers`](https://github.com/huggingface/transformers) - provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio. The documentation for this library can be found [`here`](https://huggingface.co/docs/transformers/installation).
- [`pattern`](https://github.com/clips/pattern) - a web mining module for Python, with tools for scraping, natural language processing, machine learning, network analysis and visualization. The documentation for this library can be found [`here`](https://github.com/clips/pattern/wiki).
- [`polyglot`](https://github.com/aboSamoor/polyglot) - supports various multilingual applications and offers a wide range of analysis and broad language coverage. The documentation for this library can be found [`here`](https://polyglot.readthedocs.io/en/latest/).
- [`vaderSentiment`](https://github.com/cjhutto/vaderSentiment) - a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.
- [`word_forms`](https://github.com/gutfeeling/word_forms) - accurately generate all possible forms of an English word. The documentation for this library can be found [`here`](https://github.com/gutfeeling/word_forms/blob/master/README.md).

### Computer Vision

- [`NiLearn`](https://github.com/nilearn/nilearn) - makes it easy to use many advanced machine learning, pattern recognition and multivariate statistical techniques on neuroimaging data. The documentation for this library can be found [`here`](https://nilearn.github.io/stable/user_guide.html).
- [`OpenCV`](https://github.com/opencv/opencv) - an open-source library that includes several hundreds of computer vision algorithms. The documentation for this library can be found [`here`](https://docs.opencv.org/4.x/).

### Miscalleneous

- [`Google Python Style Guide`](https://github.com/google/styleguide/blob/gh-pages/pyguide.md#39-classes) - a good style guide to follow when developing in Python.
- [`black`](https://github.com/psf/black) - the uncompromising Python code formatter.
